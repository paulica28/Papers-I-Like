{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "330530de-dc37-44d1-aada-bbb9dacde3ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "import torchdiffeq\n",
    "from typing import Callable\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b6069bf8-edec-4c38-82fc-03a13f7e89e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PerformanceContainer(object):\n",
    "    \"\"\" Simple data class for metrics logging.\"\"\"\n",
    "    def __init__(self, data:dict):\n",
    "        self.data = data\n",
    "        \n",
    "    @staticmethod\n",
    "    def deep_update(x, y):\n",
    "        for key in y.keys():\n",
    "            x.update({key: list(x[key] + y[key])})\n",
    "        return x\n",
    "    \n",
    "def accuracy(y_hat:torch.Tensor, y:torch.Tensor):\n",
    "    \"\"\" Standard percentage accuracy computation \"\"\"\n",
    "    preds = torch.max(y_hat, 1)[1]\n",
    "    return torch.mean((y == preds).float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd6683b4-5897-4497-8fdd-b9ca78c6480b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# seed for repeatability\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d25888f6-8b9d-4aee-9006-9a54b0c0ab9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 140, 500, 1000)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed for repeatability\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Load the Cora dataset using torch_geometric\n",
    "dataset = datasets.Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "# Features and labels\n",
    "X = data.x.to(device)\n",
    "Y = data.y.to(device)\n",
    "\n",
    "# Masks for training, validation, and test\n",
    "train_mask = data.train_mask.to(device)\n",
    "val_mask = data.val_mask.to(device)\n",
    "test_mask = data.test_mask.to(device)\n",
    "\n",
    "# Number of features and classes\n",
    "num_feats = X.shape[1]\n",
    "num_classes = dataset.num_classes\n",
    "\n",
    "# Summary\n",
    "num_classes, train_mask.sum().item(), val_mask.sum().item(), test_mask.sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "619c6a4c-04e0-4193-9d34-9c3169456027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, adj_matrix: torch.Tensor, in_feats: int, out_feats: int,\n",
    "                 activation: Callable[[torch.Tensor], torch.Tensor] = None,\n",
    "                 dropout: float = 0.0, bias: bool = True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Convert edge_index to a square adjacency matrix\n",
    "        edge_index = adj_matrix\n",
    "        num_nodes = torch.max(edge_index) + 1  # Assuming node indices start from 0\n",
    "\n",
    "        # Convert edge_index to adjacency matrix\n",
    "        adj_matrix = torch.zeros((num_nodes, num_nodes), device=edge_index.device)\n",
    "        adj_matrix[edge_index[0], edge_index[1]] = 1\n",
    "        \n",
    "        # Store the adjacency matrix\n",
    "        self.adj_matrix = adj_matrix\n",
    "        \n",
    "        # Define the layer weights and biases\n",
    "        self.weight = nn.Parameter(torch.Tensor(in_feats, out_feats))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_feats))\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        # Activation function\n",
    "        self.activation = activation\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=dropout) if dropout > 0 else nn.Identity()\n",
    "\n",
    "        # Initialize weights\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, h: torch.Tensor):\n",
    "        if self.dropout:\n",
    "            h = self.dropout(h)\n",
    "        h = torch.mm(h, self.weight)\n",
    "\n",
    "        # Compute the degree matrix\n",
    "        degree_inv_sqrt = torch.pow(self.adj_matrix.sum(dim=1), -0.5)\n",
    "        degree_inv_sqrt[torch.isinf(degree_inv_sqrt)] = 0.0\n",
    "        norm = torch.diag(degree_inv_sqrt)\n",
    "\n",
    "        # Symmetric normalization: D^(-1/2) A D^(-1/2)\n",
    "        adj_norm = torch.mm(norm, torch.mm(self.adj_matrix.float(), norm))\n",
    "\n",
    "        # Aggregation\n",
    "        h = torch.mm(adj_norm, h)\n",
    "\n",
    "        # Apply bias if necessary\n",
    "        if self.bias is not None:\n",
    "            h = h + self.bias\n",
    "\n",
    "        # Apply activation function\n",
    "        if self.activation is not None:\n",
    "            h = self.activation(h)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "54a93a6b-8e8d-48a9-897a-83a9451386c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, num_layers: int, adj_matrix: torch.Tensor, in_feats: int, hidden_feats: int,\n",
    "                 out_feats: int, activation: Callable[[torch.Tensor], torch.Tensor],\n",
    "                 dropout: float = 0.0, bias: bool = True):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        # First GCN layer\n",
    "        self.layers.append(GCNLayer(adj_matrix, in_feats, hidden_feats, activation, dropout, bias))\n",
    "\n",
    "        # Middle GCN layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.layers.append(GCNLayer(adj_matrix, hidden_feats, hidden_feats, activation, dropout, bias))\n",
    "\n",
    "        # Last GCN layer\n",
    "        self.layers.append(GCNLayer(adj_matrix, hidden_feats, out_feats, None, 0.0, bias))\n",
    "\n",
    "    def forward(self, features: torch.Tensor):\n",
    "        h = features\n",
    "        for layer in self.layers:\n",
    "            h = layer(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8dc1a14c-e117-4c66-bcf1-19d3c7ee9cff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GDEFunc(nn.Module):\n",
    "    def __init__(self, gnn: nn.Module):\n",
    "        \"\"\"General GDE function class. To be passed to an ODEBlock.\"\"\"\n",
    "        super().__init__()\n",
    "        self.gnn = gnn\n",
    "        self.nfe = 0  # Number of function evaluations (NFE)\n",
    "    \n",
    "    def set_graph(self, adj_matrix: torch.Tensor):\n",
    "        \"\"\"Set adjacency matrix for the GNN layers if needed.\"\"\"\n",
    "        for layer in self.gnn:\n",
    "            if hasattr(layer, 'adj_matrix'):\n",
    "                layer.adj_matrix = adj_matrix\n",
    "            \n",
    "    def forward(self, t, x):\n",
    "        \"\"\"Forward method to compute the GNN output.\"\"\"\n",
    "        self.nfe += 1\n",
    "        x = self.gnn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38ced699-b1a4-4d5b-9ede-90a0445c0419",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ControlledGDEFunc(GDEFunc):\n",
    "    def __init__(self, gnn: nn.Module):\n",
    "        \"\"\"Controlled GDE version. Input information is preserved longer via hooks to input node features X_0, \n",
    "           affecting all ODE function steps. Requires assignment of '.h0' before calling .forward.\"\"\"\n",
    "        super().__init__(gnn)\n",
    "        self.nfe = 0\n",
    "        self.h0 = None  # Placeholder for the initial node features\n",
    "            \n",
    "    def forward(self, t, x):\n",
    "        \"\"\"Forward method that concatenates initial node features with current features.\"\"\"\n",
    "        self.nfe += 1\n",
    "        if self.h0 is not None:\n",
    "            x = torch.cat([x, self.h0], dim=1)\n",
    "        x = self.gnn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "23223a6e-e5f5-4a42-b58e-ec2cee62fc14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ODEBlock(nn.Module):\n",
    "    def __init__(self, odefunc: nn.Module, method: str = 'dopri5', rtol: float = 1e-3, atol: float = 1e-4, adjoint: bool = True):\n",
    "        \"\"\" Standard ODEBlock class. Can handle all types of ODE functions\n",
    "            :method:str = {'euler', 'rk4', 'dopri5', 'adams'}\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.odefunc = odefunc\n",
    "        self.method = method\n",
    "        self.adjoint_flag = adjoint\n",
    "        self.atol, self.rtol = atol, rtol\n",
    "\n",
    "    def forward(self, x: torch.Tensor, T: int = 1):\n",
    "        self.integration_time = torch.tensor([0, T]).float()\n",
    "        self.integration_time = self.integration_time.type_as(x)\n",
    "\n",
    "        if self.adjoint_flag:\n",
    "            out = torchdiffeq.odeint_adjoint(self.odefunc, x, self.integration_time,\n",
    "                                             rtol=self.rtol, atol=self.atol, method=self.method)\n",
    "        else:\n",
    "            out = torchdiffeq.odeint(self.odefunc, x, self.integration_time,\n",
    "                                     rtol=self.rtol, atol=self.atol, method=self.method)\n",
    "            \n",
    "        return out[-1]\n",
    "    \n",
    "    def forward_batched(self, x: torch.Tensor, nn: int, indices: list, timestamps: set):\n",
    "        \"\"\" Modified forward for ODE batches with different integration times \"\"\"\n",
    "        timestamps = torch.Tensor(list(timestamps))\n",
    "        timestamps = timestamps.type_as(x)\n",
    "        \n",
    "        if self.adjoint_flag:\n",
    "            out = torchdiffeq.odeint_adjoint(self.odefunc, x, timestamps,\n",
    "                                             rtol=self.rtol, atol=self.atol, method=self.method)\n",
    "        else:\n",
    "            out = torchdiffeq.odeint(self.odefunc, x, timestamps,\n",
    "                                     rtol=self.rtol, atol=self.atol, method=self.method)\n",
    "\n",
    "        out = self._build_batch(out, nn, indices).reshape(x.shape)\n",
    "        return out\n",
    "    \n",
    "    def _build_batch(self, odeout, nn, indices):\n",
    "        b_out = []\n",
    "        for i in range(len(indices)):\n",
    "            b_out.append(odeout[indices[i], i*nn:(i+1)*nn])\n",
    "        return torch.cat(b_out).to(odeout.device)\n",
    "              \n",
    "    def trajectory(self, x: torch.Tensor, T: int, num_points: int):\n",
    "        self.integration_time = torch.linspace(0, T, num_points)\n",
    "        self.integration_time = self.integration_time.type_as(x)\n",
    "        out = torchdiffeq.odeint(self.odefunc, x, self.integration_time,\n",
    "                                 rtol=self.rtol, atol=self.atol, method=self.method)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "11c87b85-c5f0-42e9-a97e-c2557d114e4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13264"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the edge index to a NetworkX graph\n",
    "G = pyg_utils.to_networkx(data, to_undirected=True)\n",
    "\n",
    "# Remove existing self-loops\n",
    "G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "# Add self-loops\n",
    "G.add_edges_from(zip(G.nodes(), G.nodes()))\n",
    "\n",
    "# Convert the graph back to PyTorch Geometric format\n",
    "edge_index = pyg_utils.from_networkx(G).edge_index\n",
    "\n",
    "# Update the data object with the new edge index\n",
    "data.edge_index = edge_index\n",
    "\n",
    "# Calculate the number of edges\n",
    "n_edges = data.edge_index.size(1)\n",
    "\n",
    "n_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9b154e04-545d-4bec-9ce9-a2a1ed522aca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Compute the degrees of the nodes\n",
    "degs = pyg_utils.degree(data.edge_index[0], num_nodes=data.num_nodes).float()\n",
    "\n",
    "# Step 2: Compute the normalization values (D^-0.5)\n",
    "norm = torch.pow(degs, -0.5)\n",
    "norm[torch.isinf(norm)] = 0  # Replace infinities with zero\n",
    "\n",
    "# Step 3: Add the norm as a node feature to the data object\n",
    "data.norm = norm.unsqueeze(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "501c7ea9-a615-4c76-9d4c-fb0e01e64800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adj_matrix = edge_index.to(device)  # Assuming data.edge_index is the adjacency matrix in torch_geometric format\n",
    "\n",
    "# Create the GNN layers using the adjacency matrix\n",
    "gnn = nn.Sequential(\n",
    "    GCNLayer(adj_matrix=adj_matrix, in_feats=64, out_feats=64, activation=nn.Softplus(), dropout=0.9),\n",
    "    GCNLayer(adj_matrix=adj_matrix, in_feats=64, out_feats=64, activation=None, dropout=0.9)\n",
    ").to(device)\n",
    "\n",
    "# Define the graph ODE function\n",
    "gdefunc = GDEFunc(gnn)\n",
    "\n",
    "# Create the ODE block with the 'rk4' method\n",
    "gde = ODEBlock(odefunc=gdefunc, method='rk4', atol=1e-3, rtol=1e-4, adjoint=False).to(device)\n",
    "\n",
    "# Create the full model\n",
    "m = nn.Sequential(\n",
    "    GCNLayer(adj_matrix=adj_matrix, in_feats=num_feats, out_feats=64, activation=F.relu, dropout=0.4),\n",
    "    gde,\n",
    "    GCNLayer(adj_matrix=adj_matrix, in_feats=64, out_feats=n_classes, activation=None, dropout=0.0)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6a809981-e36d-4054-a438-f5aa1956b45e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 150/3000 [00:56<17:55,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150], Loss: 0.083, Train Accuracy: 1.000, Test Accuracy: 0.802, NFE: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 300/3000 [01:52<16:58,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300], Loss: 0.029, Train Accuracy: 1.000, Test Accuracy: 0.806, NFE: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 450/3000 [02:49<16:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[450], Loss: 0.018, Train Accuracy: 1.000, Test Accuracy: 0.807, NFE: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 600/3000 [03:46<15:04,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600], Loss: 0.018, Train Accuracy: 1.000, Test Accuracy: 0.809, NFE: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 750/3000 [04:42<14:11,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[750], Loss: 0.013, Train Accuracy: 1.000, Test Accuracy: 0.801, NFE: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 900/3000 [05:39<13:12,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[900], Loss: 0.012, Train Accuracy: 1.000, Test Accuracy: 0.808, NFE: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 1050/3000 [06:36<12:19,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1050], Loss: 0.011, Train Accuracy: 1.000, Test Accuracy: 0.806, NFE: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 1200/3000 [07:32<11:19,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200], Loss: 0.015, Train Accuracy: 1.000, Test Accuracy: 0.814, NFE: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1350/3000 [08:29<10:22,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1350], Loss: 0.015, Train Accuracy: 1.000, Test Accuracy: 0.807, NFE: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1500/3000 [09:26<09:25,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1500], Loss: 0.012, Train Accuracy: 1.000, Test Accuracy: 0.813, NFE: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 1650/3000 [10:22<08:29,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1650], Loss: 0.008, Train Accuracy: 1.000, Test Accuracy: 0.811, NFE: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1800/3000 [11:19<07:34,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1800], Loss: 0.008, Train Accuracy: 1.000, Test Accuracy: 0.801, NFE: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 1950/3000 [12:16<06:36,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1950], Loss: 0.008, Train Accuracy: 1.000, Test Accuracy: 0.809, NFE: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 2100/3000 [13:13<05:40,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2100], Loss: 0.011, Train Accuracy: 1.000, Test Accuracy: 0.807, NFE: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 2250/3000 [14:09<04:43,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2250], Loss: 0.006, Train Accuracy: 1.000, Test Accuracy: 0.823, NFE: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 2400/3000 [15:06<03:47,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2400], Loss: 0.044, Train Accuracy: 1.000, Test Accuracy: 0.820, NFE: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 2550/3000 [16:03<02:50,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2550], Loss: 0.006, Train Accuracy: 1.000, Test Accuracy: 0.811, NFE: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 2700/3000 [17:00<01:53,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2700], Loss: 0.011, Train Accuracy: 1.000, Test Accuracy: 0.809, NFE: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 2850/3000 [17:56<00:57,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2850], Loss: 0.006, Train Accuracy: 1.000, Test Accuracy: 0.821, NFE: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [18:53<00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000], Loss: 0.012, Train Accuracy: 1.000, Test Accuracy: 0.809, NFE: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Optimizer and Loss\n",
    "opt = torch.optim.Adam(m.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Performance Logging\n",
    "logger = PerformanceContainer(data={\n",
    "    'train_loss': [], 'train_accuracy': [],\n",
    "    'test_loss': [], 'test_accuracy': [],\n",
    "    'forward_time': [], 'backward_time': [],\n",
    "    'nfe': []\n",
    "})\n",
    "\n",
    "steps = 3000\n",
    "verbose_step = 150\n",
    "num_grad_steps = 0\n",
    "\n",
    "for i in tqdm(range(steps)):  # Looping over epochs\n",
    "    m.train()\n",
    "    start_time = time.time()\n",
    "\n",
    "    outputs = m(X)\n",
    "    f_time = time.time() - start_time\n",
    "\n",
    "    nfe = m._modules['1'].odefunc.nfe\n",
    "\n",
    "    y_pred = outputs\n",
    "\n",
    "    loss = criterion(y_pred[train_mask], Y[train_mask])\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    loss.backward()\n",
    "    b_time = time.time() - start_time\n",
    "    \n",
    "    opt.step()\n",
    "    num_grad_steps += 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        m.eval()\n",
    "\n",
    "        # Calculate outputs again with zeroed dropout\n",
    "        y_pred = m(X)\n",
    "        m._modules['1'].odefunc.nfe = 0\n",
    "\n",
    "        train_loss = loss.item()\n",
    "        train_acc = accuracy(y_pred[train_mask], Y[train_mask]).item()\n",
    "        test_acc = accuracy(y_pred[test_mask], Y[test_mask]).item()\n",
    "        test_loss = criterion(y_pred[test_mask], Y[test_mask]).item()\n",
    "\n",
    "        logger.deep_update(logger.data, dict(\n",
    "            train_loss=[train_loss],\n",
    "            train_accuracy=[train_acc],\n",
    "            test_loss=[test_loss],\n",
    "            test_accuracy=[test_acc],\n",
    "            nfe=[nfe],\n",
    "            forward_time=[f_time],\n",
    "            backward_time=[b_time]\n",
    "        ))\n",
    "\n",
    "    if num_grad_steps % verbose_step == 0:\n",
    "        print(f'[{num_grad_steps}], Loss: {train_loss:.3f}, Train Accuracy: {train_acc:.3f}, '\n",
    "              f'Test Accuracy: {test_acc:.3f}, NFE: {nfe}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7cc3ac-f92e-4be0-81f3-954fabc7d924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
